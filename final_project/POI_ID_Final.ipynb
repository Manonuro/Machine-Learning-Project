{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers Before Removal of TOTAL : ['LAY KENNETH L', 'SKILLING JEFFREY K', 'TOTAL']\n",
      "ave_earnings is the average value of: ['salary', 'bonus', 'deferral_payments', 'total_payments']\n",
      "\n",
      " Features List:\n",
      "\n",
      "['poi',\n",
      " 'salary',\n",
      " 'bonus',\n",
      " 'deferral_payments',\n",
      " 'total_payments',\n",
      " 'ave_earnings',\n",
      " 'deferred_income',\n",
      " 'total_stock_value',\n",
      " 'exercised_stock_options',\n",
      " 'restricted_stock',\n",
      " 'restricted_stock_deferred',\n",
      " 'expenses',\n",
      " 'long_term_incentive',\n",
      " 'shared_receipt_with_poi',\n",
      " 'from_this_person_to_poi',\n",
      " 'from_poi_to_this_person',\n",
      " 'to_messages',\n",
      " 'from_messages']\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report, precision_recall_curve\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from pprint import pprint\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "\n",
    "### Task 1: Select what features you'll use.\n",
    "### features_list is a list of strings, each of which is a feature name.\n",
    "### The first feature must be \"poi\".\n",
    "\n",
    "\n",
    "features_list = ['poi', 'salary', 'bonus', 'deferral_payments', 'total_payments', 'ave_earnings', \n",
    "                 'deferred_income','total_stock_value', 'exercised_stock_options', \n",
    "                'restricted_stock', 'restricted_stock_deferred', 'expenses',  \n",
    "                 'long_term_incentive', 'shared_receipt_with_poi', \n",
    "                 'from_this_person_to_poi','from_poi_to_this_person',\n",
    "                'to_messages','from_messages'] \n",
    "\n",
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n",
    "\n",
    "### Task 2: Remove outliers\n",
    "# List of all keys of the data_dict for  salary value > 1 million and \n",
    "# bonus > 5 million dollars\n",
    "outliers = []\n",
    "for e in data_dict.keys():\n",
    "    if data_dict[e][\"salary\"] != 'NaN' and data_dict[e]['salary'] > 1000000 and data_dict[e]['bonus'] > 5000000:\n",
    "        outliers.append(e)\n",
    "        \n",
    "print \"Outliers Before Removal of TOTAL :\",outliers\n",
    "\n",
    "data_dict.pop('TOTAL',0)\n",
    "\n",
    "\n",
    "### Task 3: Create new feature(s)\n",
    "### Store to my_dataset for easy export below.\n",
    "\n",
    "my_dataset = data_dict\n",
    "\n",
    "#### I will add a new feature that shows average value of total earning called ave_earnings \n",
    "#### by calculating the mean value of 'salary', 'bonus', 'deferral_payments', and 'total_payments' for each person.\n",
    "\n",
    "for ele in my_dataset:\n",
    "    earnings = []\n",
    "    for e in features_list[1:5]:\n",
    "        earn = my_dataset[ele][e]\n",
    "        if earn =='NaN':\n",
    "            earn = 0\n",
    "            earnings.append(earn)\n",
    "        earnings.append(earn)\n",
    "    ave_earnings = np.mean(earnings)\n",
    "    my_dataset[ele].update({'ave_earnings': ave_earnings})\n",
    "\n",
    "print 'ave_earnings is the average value of:', features_list[1:5]\n",
    "\n",
    "      \n",
    "       \n",
    "###Extract features and labels from dataset for local testing\n",
    "# I removed entries with all 'NaN' values or all '0' in order to clean up data and avoid any problem on calcultions.\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True, remove_NaN=True,\n",
    "                     remove_all_zeroes=True, remove_any_zeroes=False)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "print \"\\n Features List:\\n\"\n",
    "pprint (features_list)\n",
    "\n",
    "\n",
    "\n",
    "### Task 4: Try a varity of classifiers\n",
    "\n",
    "# I tried several different classifiers and their output results of the tester.py script\n",
    "# in the ML_project_varity_of_classifiers.ipny file\n",
    "# Provided to give you a starting point. Try a variety of classifiers.\n",
    "#from sklearn.naive_bayes import GaussianNB\n",
    "#from sklearn import cross_validation\n",
    "\n",
    "\n",
    "\n",
    "### Task 5: Tune your classifier to achieve better than .3 precision and recall \n",
    "### using our testing script. Check the tester.py script in the final project\n",
    "### folder for details on the evaluation method, especially the test_classifier\n",
    "### function. Because of the small size of the dataset, the script uses\n",
    "### stratified shuffle split cross validation. For more info: \n",
    "### http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.StratifiedShuffleSplit.html\n",
    "\n",
    "# Below is the clasifier with best precision result above .3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = featureFormat(my_dataset, features_list)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "feature_train, feature_test, label_train, label_test = train_test_split( \n",
    "features, labels, test_size=0.3,random_state=42)\n",
    "\n",
    "skb = SelectKBest(k=2)\n",
    "svc = SVC(C=1000, gamma=.001, kernel='linear')\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "clf = Pipeline(steps=[('scaling',scaler),(\"skb\", skb), (\"svc\", svc)])\n",
    "\n",
    "\n",
    "### Task 6: Dump your classifier, dataset, and features_list so anyone can\n",
    "### check your results. You do not need to change anything below, but make sure\n",
    "### that the version of poi_id.py that you submit can be run on its own and\n",
    "### generates the necessary .pkl files for validating your results.\n",
    "\n",
    "\n",
    "dump_classifier_and_data(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
